---
title: "Lab 11 - Moderation and Interactions"
output: html_document
date: "2024-10-09"
---

# Lab 11 Goals

- See the progression of a simulation
- Interpret interactions and mediation
- Create your own simulation
- Simulate interactions and mediation

# Part 1: The setup

Imagine a community of tree frogs. In this community there's competition for resources which mean that the frogs end up weighing different amounts. However, all else being equal, heavier frogs are able to lay more eggs than lighter frogs. (For this example we're only considering frogs who can lay eggs). Of course, other factors than frog weight influence the number of eggs, so there's some noise. We can simulate the relationship between frog weight (in grams) and the number of eggs they lay (the average is 4,500!!).


```{r load data}
library(tidyverse)
library(huxtable)
library(ggeffects)
```


# Part 2: Basic Simulation

The sim code chunk simulates a community of frogs.

```{r sim}
# We'll make a data frame
# we have 1000 frogs
n = 1000
frog_df <- tibble(
  # average weight is 22.7 with sd of 3
  weight = rnorm(n,22.7,3)
)

# we can use mutate to simulate the number of eggs
frog_df <- frog_df %>%
  # eggs equals an intercept plus 100 times weight plus error
  mutate(eggs = 2230 + 100*weight + rnorm(n,0,400))
```

Let's see how our handywork looks.

```{r}
# look at the distribution of weights
ggplot(frog_df, aes(weight))+
  geom_histogram()
  
# as expected, we see a clear linear relationship
ggplot(frog_df, aes(weight, eggs))+
  geom_point()

```


Now we can fit a regression and then summarize and visualize the results

```{r}
weight1 <- lm(eggs ~ weight, data = frog_df)
summary(weight1)
```

```{r}
pred1 <- ggpredict(weight1, terms = 'weight')
plot(pred1)+
  # adjusting the y-axis to start at zero and go one sd above the max observed value
  ylim(0, max(frog_df$eggs+sd(frog_df$eggs)))+
  xlim(-5,40)+
  geom_hline(yintercept = 0, color = 'red')+
  geom_vline(xintercept = 0, color = 'red')
```

## Questions
1. Does the regression effectively recover the true coefficient value? Why or why not?
2. Do you think the association with weight is statistically significant? Practically significant?

# Part 3: Leveled up Simulation

Let's redo this, but complicate the relationship. For one, frogs, being amphibians, need access to water. Maybe frogs who lay their eggs closer to water will lay more eggs, since the conditions are better. Also, it's common for relationships of distance to be logarithmic -- being one meter from water is a lot better than being two meters from water, but being 10m from water isn't much better than being 11m from water.

```{r}
frog_df <- frog_df %>%
  mutate(
    # distance from water in meters -- heavier frogs get to be closer
    water_dist = (1.01-weight/max(weight))*rgamma(n,1),
    # new formula for eggs, including the distance from water
    eggs = 2230 + 100*weight - 150*log(water_dist) + rnorm(n,0,400))

```
  
Let's plot our new relationship
  
```{r}
# now we have two variables
frog_df %>% pivot_longer(-eggs) %>%
ggplot(aes(value, eggs, color = name))+
  geom_point()+
  geom_smooth()+
  facet_wrap(~name, scales = 'free')
```
  
Now we'll fit a buch of models:

```{r}
# bivariate eggs and weight
weight2 <- lm(eggs ~ weight, data = frog_df)

# bivariate eggs and dist - level-level
level_dist2 <- lm(eggs ~ water_dist, data = frog_df)

# bivariate eggs and dist - level-log
log_dist2 <- lm(eggs ~ log(water_dist), data = frog_df)

# multiple regression with weight and log dist
weight_dist2 <- lm(eggs ~ weight + log(water_dist), data = frog_df)

# modifying huxreg to have informative names and adjust r squared
huxreg(list('Bivariate' = weight2, 'Level Distance' = level_dist2, 'Logged Distance' = log_dist2, 'Weight and Logged Distance' = weight_dist2),
       statistics = c(N = "nobs", R2 = "r.squared", "Adjusted R2" = 'adj.r.squared', "logLik", "AIC"))
```
  
And we can plot predictions
  
```{r}
pred2 <- ggpredict(weight_dist2, terms = c('weight', 'water_dist [0.1,1,10]'))
plot(pred2) + ylim(0, max(frog_df$eggs+sd(frog_df$eggs)))
```



## Questions:
1. Compare the coefficient for weight in the bivariate model (weight2) and in the 'Weight and Logged Distance' model (weight_dist2). What accounts for that difference?
2. Why does model 3 (log_dist2) fit better than model 2 (level_dist2)?
3. Looking at the predicted values plot, describe and explain the difference between the lines in the plot.

# Part 4 - Genetic mutation 1

OK, so far, so good. I guess. Imagine that some frogs have a random mutation
which increases the number of eggs that they lay by 500.

```{r}
frog_df <- frog_df %>%
  mutate(
    mutation1 = if_else(rnorm(n)>0,1,0),
    # new formula for eggs, including mutation 1
    eggs = 2230 + 100*weight - 150*log(water_dist) + 500*mutation1 + rnorm(n,0,400))

frog_df %>% pivot_longer(-eggs) %>%
  ggplot(aes(value, eggs, color = name))+
  geom_point()+
  geom_smooth()+
  facet_wrap(~name, scales = 'free')
```

Fit new models and make a table

```{r}
# bivariate eggs and weight
weight3 <- lm(eggs ~ weight, data = frog_df)

# multiple regression with weight and log dist
weight_dist3 <- lm(eggs ~ weight + log(water_dist), data = frog_df)

# multiple regression with weight and log dist
full3 <- lm(eggs ~ weight + log(water_dist) + mutation1, data = frog_df)


huxreg(list('Bivariate' = weight3, 'Weight and Log Dist' = weight_dist3, 'Plus Mutation' = full3),
       statistics = c(N = "nobs", R2 = "r.squared", "Adjusted R2" = 'adj.r.squared', "logLik", "AIC"))
```


And a plot:
```{r}
pred3 <- ggpredict(full3, terms = c('weight', 'mutation1'))
plot(pred3) + ylim(0, max(frog_df$eggs+sd(frog_df$eggs)))
```



## Questions:
1. Compare the coefficients for weight and water_dist in the 'Weight and Log Dist' model (weight_dist3) and in the 'Plus Mutation' model (full3). What accounts for that difference?
2. Why does the 'Plus Mutation' model (full3) fit better than the 'Weight and Log Dist' model (weight_dist3)?
3. Looking at the predicted values plot, describe and explain the difference between the lines in the plot.

# Part 4 - Mutation 2

In the final part of our simulation, imagine a second mutation. It's just as random as the first one -- ie, it's not associated with weight -- but it works differently. Instead of just increasing the number of eggs laid, this mutation works better on heavier frogs. When a frog is heavy, mutation 2 produces a lot of extra eggs. But when a frog is not that heavy, mutation 2 produces only a few extra eggs. This is an example of an interaction, or moderation. The weight _moderates_ the effect of the mutation, so that the effect of the mutation is different at different weights. Let's check it out.

Simulating again:
```{r}
frog_df <- frog_df %>%
  mutate(
    mutation2 = if_else(rnorm(n)>0,1,0),
    # new formulat for eggs, including mutation 1
    eggs = 2000 + 100*weight - 150*log(water_dist) + 500*mutation1 + 80*mutation2*weight + rnorm(n,0,400))

frog_df %>% pivot_longer(-eggs) %>%
  ggplot(aes(value, eggs, color = name))+
  geom_point()+
  geom_smooth()+
  facet_wrap(~name, scales = 'free')
```

And fitting new models

```{r}
# bivariate eggs and weight
weight4 <- lm(eggs ~ weight, data = frog_df)

# additive effect of mutation 2
additive4 <- lm(eggs ~ weight + log(water_dist) + mutation1 + mutation2, data = frog_df)

# moderation and additive effect of mutation 2
interaction4 <- lm(eggs ~ weight + log(water_dist) + mutation1 + mutation2 + I(mutation2*weight), data = frog_df)

huxreg(list('Bivariate' = weight4, 'Additive' = additive4, 'Interaction' = interaction4),
       statistics = c(N = "nobs", R2 = "r.squared", "Adjusted R2" = 'adj.r.squared', "logLik", "AIC"))
```


And a plot, of course:
```{r}
pred4 <- ggpredict(interaction4, terms = c('weight', 'mutation2'))
plot(pred4) + ylim(0, max(frog_df$eggs+sd(frog_df$eggs)))
```


## Questions:
1. Compare the coefficients for weight and water_dist in the Bivariate (weight4),  Additive (additive4) and in Interaction (interaction4) models. What accounts for that difference?
2. Why does the Interaction model (interaction4) fit better than the Additive model (additive4)?
3. Looking at the predicted values plot, describe and explain the difference between the lines in the plot.
4. Can you think of an example of a real-life interaction?


# Lab 11 Checkout

1. You'll be creating your own simulation. It can be of anything, but if you can't think of anything, just do student test scores. Describe your setting.
2. Create your basic cause, like 'intelligence' or 'hard work'. Use that to produce test scores. Use regression modeling and visualization to check if you can recover the coefficients.
3. Modify your simulation to include a mediating variable and a moderating variable. Model the new data, plot it, and interpret the models and the plots.
